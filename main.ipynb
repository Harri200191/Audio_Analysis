{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import easygui\n",
    "import speech_recognition as sr\n",
    "import pydub\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_audio_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        print(\"File is being read......\")\n",
    "        audio = recognizer.record(source)  # Read the entire audio file\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)  # Use Google Web Speech API for recognition\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Google Web Speech API could not understand the audio\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Could not request results from Google Web Speech API; {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Audio file could not be read as PCM WAV, AIFF/AIFF-C, or Native FLAC; check if file is corrupted or in another format",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\speech_recognition\\__init__.py:241\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[39m# attempt to read the file as WAV\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio_reader \u001b[39m=\u001b[39m wave\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename_or_fileobject, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlittle_endian \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\wave.py:631\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 631\u001b[0m     \u001b[39mreturn\u001b[39;00m Wave_read(f)\n\u001b[0;32m    632\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\wave.py:283\u001b[0m, in \u001b[0;36mWave_read.__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 283\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitfp(f)\n\u001b[0;32m    284\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\wave.py:250\u001b[0m, in \u001b[0;36mWave_read.initfp\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file\u001b[39m.\u001b[39mgetname() \u001b[39m!=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRIFF\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m     \u001b[39mraise\u001b[39;00m Error(\u001b[39m'\u001b[39m\u001b[39mfile does not start with RIFF id\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    251\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file\u001b[39m.\u001b[39mread(\u001b[39m4\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mWAVE\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[1;31mError\u001b[0m: file does not start with RIFF id",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\speech_recognition\\__init__.py:246\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    245\u001b[0m     \u001b[39m# attempt to read the file as AIFF\u001b[39;00m\n\u001b[1;32m--> 246\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio_reader \u001b[39m=\u001b[39m aifc\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename_or_fileobject, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    247\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlittle_endian \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# AIFF is a big-endian format\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\aifc.py:954\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 954\u001b[0m     \u001b[39mreturn\u001b[39;00m Aifc_read(f)\n\u001b[0;32m    955\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\aifc.py:358\u001b[0m, in \u001b[0;36mAifc_read.__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 358\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitfp(file_object)\n\u001b[0;32m    359\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\aifc.py:322\u001b[0m, in \u001b[0;36mAifc_read.initfp\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mif\u001b[39;00m chunk\u001b[39m.\u001b[39mgetname() \u001b[39m!=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFORM\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 322\u001b[0m     \u001b[39mraise\u001b[39;00m Error(\u001b[39m'\u001b[39m\u001b[39mfile does not start with FORM id\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    323\u001b[0m formdata \u001b[39m=\u001b[39m chunk\u001b[39m.\u001b[39mread(\u001b[39m4\u001b[39m)\n",
      "\u001b[1;31mError\u001b[0m: file does not start with FORM id",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\speech_recognition\\__init__.py:272\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio_reader \u001b[39m=\u001b[39m aifc\u001b[39m.\u001b[39;49mopen(aiff_file, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    273\u001b[0m \u001b[39mexcept\u001b[39;00m (aifc\u001b[39m.\u001b[39mError, \u001b[39mEOFError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\aifc.py:954\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 954\u001b[0m     \u001b[39mreturn\u001b[39;00m Aifc_read(f)\n\u001b[0;32m    955\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\aifc.py:364\u001b[0m, in \u001b[0;36mAifc_read.__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    363\u001b[0m     \u001b[39m# assume it is an open file object already\u001b[39;00m\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitfp(f)\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\aifc.py:320\u001b[0m, in \u001b[0;36mAifc_read.initfp\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m file\n\u001b[1;32m--> 320\u001b[0m chunk \u001b[39m=\u001b[39m Chunk(file)\n\u001b[0;32m    321\u001b[0m \u001b[39mif\u001b[39;00m chunk\u001b[39m.\u001b[39mgetname() \u001b[39m!=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFORM\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\chunk.py:67\u001b[0m, in \u001b[0;36mChunk.__init__\u001b[1;34m(self, file, align, bigendian, inclheader)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunkname) \u001b[39m<\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[1;32m---> 67\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mEOFError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m audio_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMainAudio.mp3\u001b[39m\u001b[39m\"\u001b[39m \n\u001b[1;32m----> 2\u001b[0m text \u001b[39m=\u001b[39m convert_audio_to_text(audio_file)\n\u001b[0;32m      4\u001b[0m \u001b[39mif\u001b[39;00m text:\n\u001b[0;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTranscription:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m, in \u001b[0;36mconvert_audio_to_text\u001b[1;34m(audio_file)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_audio_to_text\u001b[39m(audio_file):\n\u001b[0;32m      2\u001b[0m     recognizer \u001b[39m=\u001b[39m sr\u001b[39m.\u001b[39mRecognizer()\n\u001b[1;32m----> 4\u001b[0m     \u001b[39mwith\u001b[39;49;00m sr\u001b[39m.\u001b[39;49mAudioFile(audio_file) \u001b[39mas\u001b[39;49;00m source:\n\u001b[0;32m      5\u001b[0m         \u001b[39mprint\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mFile is being read......\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m         audio \u001b[39m=\u001b[39;49m recognizer\u001b[39m.\u001b[39;49mrecord(source)  \u001b[39m# Read the entire audio file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\speech_recognition\\__init__.py:274\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio_reader \u001b[39m=\u001b[39m aifc\u001b[39m.\u001b[39mopen(aiff_file, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    273\u001b[0m         \u001b[39mexcept\u001b[39;00m (aifc\u001b[39m.\u001b[39mError, \u001b[39mEOFError\u001b[39;00m):\n\u001b[1;32m--> 274\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAudio file could not be read as PCM WAV, AIFF/AIFF-C, or Native FLAC; check if file is corrupted or in another format\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    275\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlittle_endian \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# AIFF is a big-endian format\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio_reader\u001b[39m.\u001b[39mgetnchannels() \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mAudio must be mono or stereo\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Audio file could not be read as PCM WAV, AIFF/AIFF-C, or Native FLAC; check if file is corrupted or in another format"
     ]
    }
   ],
   "source": [
    "audio_file = \"MainAudio.mp3\" \n",
    "text = convert_audio_to_text(audio_file)\n",
    "\n",
    "if text:\n",
    "    print(\"Transcription:\")\n",
    "    print(text)\n",
    "else:\n",
    "    print(\"No text could be transcribed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
